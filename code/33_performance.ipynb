{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/dev/Others/yerko/other/csc/code\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/dev/Others/yerko/other/csc/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops\n",
    "import cv2\n",
    "import imagehash\n",
    "\n",
    "\n",
    "THRESHOLD = 20\n",
    "\n",
    "cv2.setNumThreads(1)\n",
    "\n",
    "\n",
    "def remove_padding(image):\n",
    "    mode = image.mode\n",
    "    image = image.convert(\"RGB\")\n",
    "    background_color_1 = image.getpixel((0, 0))\n",
    "    background = Image.new(image.mode, image.size, background_color_1)\n",
    "    difference = ImageChops.difference(image, background)\n",
    "    difference = ImageChops.add(difference, difference, 2.0, -THRESHOLD)\n",
    "    bbox = difference.getbbox()\n",
    "    if bbox:\n",
    "        image = image.crop(bbox)\n",
    "    w, h = image.size\n",
    "    background_color_2 = image.getpixel((w - 1, h - 1))\n",
    "    background = Image.new(image.mode, image.size, background_color_2)\n",
    "    difference = ImageChops.difference(image, background)\n",
    "    difference = ImageChops.add(difference, difference, 2.0, -THRESHOLD)\n",
    "    bbox = difference.getbbox()\n",
    "    if bbox:\n",
    "        image = image.crop(bbox)\n",
    "    return image.convert(mode)\n",
    "\n",
    "\n",
    "def orb_similarity(img1, img2):\n",
    "    orb = cv2.ORB_create()\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    try:\n",
    "        img1 = np.array(img1.convert(\"L\"))\n",
    "        img2 = np.array(img2.convert(\"L\"))\n",
    "        kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "        kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        good_matches_count = 0\n",
    "        for pair in matches:\n",
    "            try:\n",
    "                m, n = pair\n",
    "                if m.distance < 0.7 * n.distance:\n",
    "                    good_matches_count += 1\n",
    "\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        similarity = 2 * good_matches_count / (len(kp1) + len(kp2))\n",
    "        return similarity\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    # except Exception:\n",
    "    #     return None\n",
    "\n",
    "\n",
    "def get_features(img1, img2):\n",
    "    return {\n",
    "        \"unpadded.ahash_8\": imagehash.average_hash(img1, hash_size=8) - imagehash.average_hash(img2, hash_size=8),\n",
    "        \"unpadded.colorhash_21\": imagehash.colorhash(img1, binbits=21) - imagehash.colorhash(img2, binbits=21),\n",
    "        \"unpadded.dhash_8\": imagehash.dhash(img1, hash_size=8) - imagehash.dhash(img2, hash_size=8),\n",
    "        \"unpadded.phash_8\": imagehash.phash(img1, hash_size=8) - imagehash.phash(img2, hash_size=8),\n",
    "        \"unpadded.orb_similarity\": orb_similarity(img1, img2),\n",
    "        \"unpadded.whash_8_haar\": imagehash.whash(img1, 8, mode=\"haar\") - imagehash.whash(img2, 8, mode=\"haar\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def predict(model, img1, img2):\n",
    "    img1 = remove_padding(img1)\n",
    "    img2 = remove_padding(img2)\n",
    "    feats = get_features(img1, img2)\n",
    "\n",
    "    \n",
    "    return model.predict(pd.DataFrame(feats, index=[0]), num_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = pd.read_pickle(f\"../models/lgbm_v2.9_orb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creds import MONGO_SERVER_URL\n",
    "\n",
    "feats = list(MongoClient(MONGO_SERVER_URL).csc.featurestore.find({\"is_test\": False}, [\"image_url1\", \"image_url2\"], limit=1000))\n",
    "pairs = [\n",
    "    (\n",
    "        Image.open(\"../dataset/images_train/\" + x[\"image_url1\"]),\n",
    "        Image.open(\"../dataset/images_train/\" + x[\"image_url2\"]),\n",
    "    )\n",
    "    for x in feats\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 20s, sys: 4.29 s, total: 4min 24s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for img1, img2 in pairs[:1000]:\n",
    "    predict(clf, img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 * 60 + 24) / 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
